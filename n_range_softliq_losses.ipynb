{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook downloads the latest user snapshot data from the crvUSD subgraph and processes it to find the losses from soft liquidation in different band ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This first portion of code manages the downloading and saving the data as a CSV called user_snapshots.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pluck\n",
    "import pandas as pd\n",
    "\n",
    "# crvusd subgraph url\n",
    "subgraph_url = 'https://api.thegraph.com/subgraphs/name/convex-community/crvusd'\n",
    "\n",
    "# function to get a portion of user data\n",
    "def get_user_data(skip_snapshots=0, skip_user_states=0):\n",
    "  query = f\"\"\"\n",
    "  {{\n",
    "    snapshots(first: 1000, skip: {skip_snapshots}, where: {{userStateSnapshot: true}}) {{\n",
    "      basePrice\n",
    "      oraclePrice\n",
    "      activeBand\n",
    "      rate\n",
    "      userStates (first: 1000, skip: {skip_user_states}) {{\n",
    "        collateral\n",
    "        stablecoin\n",
    "        n\n",
    "        n1\n",
    "        n2\n",
    "        debt\n",
    "        depositedCollateral\n",
    "        health\n",
    "        loss\n",
    "        lossPct\n",
    "        timestamp\n",
    "        user {{\n",
    "          id\n",
    "        }}\n",
    "      }}\n",
    "      market {{\n",
    "        id\n",
    "        collateralName\n",
    "      }}\n",
    "    }}\n",
    "  }}\n",
    "  \"\"\"\n",
    "  frame, = pluck.execute(query, column_names=\"short\", url=subgraph_url)\n",
    "  return frame\n",
    "\n",
    "# function to get all user data\n",
    "def fetch_all_user_data():\n",
    "    skip_snapshots = 0\n",
    "    snapshot_df = pd.DataFrame()\n",
    "    \n",
    "    while True:\n",
    "        skip_user_states = 0\n",
    "        \n",
    "        while True:\n",
    "            print(f\"skip snapshots: {skip_snapshots}, user states: {skip_user_states}, snapshot_df length: {snapshot_df.shape[0]}\")\n",
    "            data = get_user_data(skip_snapshots, skip_user_states)\n",
    "            if(data.shape[1] == 18) and not data.isin(snapshot_df).all().all():\n",
    "                snapshot_df = pd.concat([snapshot_df, data], ignore_index=True)\n",
    "                skip_user_states += 1000\n",
    "            elif skip_user_states == 0:\n",
    "                return snapshot_df\n",
    "            else:\n",
    "                break\n",
    "        skip_snapshots += 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skip snapshots: 0, user states: 0, snapshot_df length: 0\n",
      "skip snapshots: 0, user states: 1000, snapshot_df length: 82037\n",
      "skip snapshots: 1000, user states: 0, snapshot_df length: 82037\n",
      "skip snapshots: 1000, user states: 1000, snapshot_df length: 129563\n",
      "skip snapshots: 2000, user states: 0, snapshot_df length: 129563\n",
      "skip snapshots: 2000, user states: 1000, snapshot_df length: 431443\n",
      "skip snapshots: 3000, user states: 0, snapshot_df length: 431443\n",
      "skip snapshots: 3000, user states: 1000, snapshot_df length: 775489\n",
      "skip snapshots: 4000, user states: 0, snapshot_df length: 775489\n",
      "skip snapshots: 4000, user states: 1000, snapshot_df length: 956056\n",
      "skip snapshots: 5000, user states: 0, snapshot_df length: 956056\n",
      "skip snapshots: 5000, user states: 1000, snapshot_df length: 1132347\n",
      "skip snapshots: 6000, user states: 0, snapshot_df length: 1132347\n"
     ]
    }
   ],
   "source": [
    "# fetch all user data\n",
    "data = fetch_all_user_data()\n",
    "\n",
    "# clean, make types correct and rename columns\n",
    "data = data.dropna()\n",
    "columns_to_int = ['activeBand', 'n', 'n1', 'n2', 'timestamp']\n",
    "columns_to_float = [\n",
    "    'basePrice', 'oraclePrice', 'collateral', 'stablecoin', 'debt',\n",
    "    'depositedCollateral', 'health', 'loss', 'lossPct', 'rate'\n",
    "]\n",
    "data[columns_to_int] = data[columns_to_int].astype(int)\n",
    "data[columns_to_float] = data[columns_to_float].astype(float)\n",
    "data = data.rename(columns={'id': 'marketId', 'user.id': 'user'})\n",
    "\n",
    "# create some columns\n",
    "data['softLiq'] = data['activeBand'] >= data['n1']\n",
    "data['collateralUsd'] = data['collateral'] * data['oraclePrice']\n",
    "\n",
    "# save to csv\n",
    "data.to_csv(\"user_snapshots.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This portion calculates the losses from the user snapshots.  If you have already downloaded the snapshots, you can just run the notebook from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# if you want the data, run the get_data.ipynb notebook first, this will pull all the latest snapshots.\n",
    "data = pd.read_csv('df_grouped.csv')\n",
    "\n",
    "# find the portion of collateral in crvUSD and the collateral token as a percentage\n",
    "data['collateralPct'] = data['collateralUsd']/(data['collateralUsd']+data['stablecoin'])*100\n",
    "data['stablecoinPct'] = 100-data['collateralPct']\n",
    "\n",
    "# currently softLiq column is True even when under softliq, let's create new columns to show the real soft liquidation\n",
    "data['under_softLiq'] = data['collateralPct'].eq(0)\n",
    "data['real_softLiq'] = (~data['under_softLiq']) & (data['softLiq'])\n",
    "\n",
    "# find the loan to value ratio\n",
    "data['ltv'] = data['debt']/(data['collateralUsd']+data['stablecoin'])*100\n",
    "\n",
    "#data['n1Price'] = data['basePrice'] * (99/100) ** data['n1']\n",
    "#data['n2Price'] = data['basePrice'] * (99/100) ** (data['n2']+1)\n",
    "# sort the data by user, marketId and timestamp\n",
    "data = data.sort_values(by=['user', 'marketId', 'timestamp']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import json\n",
    "\n",
    "def format_data(csv_file, aaveLiqRatio):\n",
    "\n",
    "    # Read the CSV file\n",
    "    data = pd.read_csv(csv_file)\n",
    "    data['collateralTotalValue'] = data['collateralUsd']+data['stablecoin']\n",
    "    data['collateralPct'] = data['collateralUsd']/(data['collateralTotalValue'])*100\n",
    "    data['stablecoinPct'] = 100-data['collateralPct']\n",
    "    time_initial = data.iloc[0]['timestamp']\n",
    "    data['timeDays'] = (data['timestamp']-time_initial)/86400\n",
    "    data['ltv'] = data['debt']/(data['collateralTotalValue'])*100\n",
    "    data['timestampYrsDiff'] = (data['timestamp'] - data['timestamp'].shift(1))/365.25/60/60/24\n",
    "    data['debtDiff'] = data['rate'] * data['debt'] * data['timestampYrsDiff']\n",
    "    data['debtAccum'] = data['debtDiff'].cumsum()\n",
    "    data['interestDebt'] = data['debtAccum']/data['collateralTotalValue']*100\n",
    "    data['totalLossPct'] = data['lossPct'] + data['interestDebt']\n",
    "    data['depositedCollateralPct'] = data['depositedCollateral']/data['depositedCollateral'].max()*100\n",
    "    data['healthFixed'] =  data['health'] + (data['stablecoin'] == 0) * data['collateral'] * (data['oraclePrice']-data['n1Price'])/data['debt']\n",
    "    data['aaveLiqPrice'] = data['debt']/aaveLiqRatio/data['depositedCollateral']\n",
    "    \n",
    "    # Round the values to 2 decimal points\n",
    "    data = data.fillna(0)\n",
    "\n",
    "    # Convert the preprocessed data to a dictionary\n",
    "    chart_data = {\n",
    "        'timeDays': data['timeDays'].apply(lambda x: f\"{x:.2f}\").tolist(),\n",
    "        'oraclePrice': data['oraclePrice'].apply(lambda x: f\"{x:.2f}\").tolist(),\n",
    "        'lossPct': data['lossPct'].apply(lambda x: f\"{x:.2f}\").tolist(),\n",
    "        'totalLossPct': data['totalLossPct'].apply(lambda x: f\"{x:.2f}\").tolist(),\n",
    "        'collateralPct': data['collateralPct'].apply(lambda x: f\"{x:.2f}\").tolist(),\n",
    "        'stablecoinPct': data['stablecoinPct'].apply(lambda x: f\"{x:.2f}\").tolist(),\n",
    "        'health': (data['healthFixed'] * 100).apply(lambda x: f\"{x:.2f}\").tolist(),\n",
    "        'ltv': data['ltv'].apply(lambda x: f\"{x:.2f}\").tolist(),\n",
    "        'n1Price': data['n1Price'].apply(lambda x: f\"{x:.2f}\").tolist(),\n",
    "        'n2Price': data['n2Price'].apply(lambda x: f\"{x:.2f}\").tolist(),\n",
    "        'collateralTotalValue': data['collateralTotalValue'].apply(lambda x: f\"{x:.2f}\").tolist(),\n",
    "        'interestDebt': data['interestDebt'].apply(lambda x: f\"{x:.2f}\").tolist(),\n",
    "        'stablecoin': data['stablecoin'].apply(lambda x: f\"{x:.2f}\").tolist(),\n",
    "        'collateralUsd': data['collateralUsd'].apply(lambda x: f\"{x:.2f}\").tolist(),\n",
    "        'debt': data['debt'].apply(lambda x: f\"{x:.2f}\").tolist(),\n",
    "        'depositedCollateralPct': data['depositedCollateralPct'].apply(lambda x: f\"{x:.2f}\").tolist(),\n",
    "        'rate': (data['rate'] * 100).apply(lambda x: f\"{x:.2f}\").tolist(),\n",
    "        'aaveLiqPrice': data['aaveLiqPrice'].apply(lambda x: f\"{x:.2f}\").tolist()\n",
    "    }\n",
    "    \n",
    "    # Save the preprocessed data as a JSON file\n",
    "    with open(csv_file.split('.')[0]+'.json', 'w') as json_file:\n",
    "        json.dump(chart_data, json_file)\n",
    "\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_70862/3499068343.py:48: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.33708333333333335' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data.at[i, 'softLiqDays'] = time_days_diff\n",
      "/tmp/ipykernel_70862/3499068343.py:49: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '5.26978543208974e-16' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data.at[i, 'lossPctPerDay'] = lossPctPerDay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3291292550280076%\n",
      "4.658258510056015%\n",
      "6.987387765084023%\n",
      "9.31651702011203%\n",
      "11.645646275140038%\n",
      "13.974775530168046%\n",
      "16.303904785196053%\n",
      "18.63303404022406%\n",
      "20.962163295252072%\n",
      "23.291292550280076%\n",
      "25.620421805308087%\n",
      "27.94955106033609%\n",
      "30.278680315364102%\n",
      "32.60780957039211%\n",
      "34.936938825420114%\n",
      "37.26606808044812%\n",
      "39.595197335476136%\n",
      "41.924326590504144%\n",
      "44.253455845532145%\n",
      "46.58258510056015%\n",
      "48.91171435558817%\n",
      "51.240843610616174%\n",
      "53.569972865644175%\n",
      "55.89910212067218%\n",
      "58.22823137570019%\n",
      "60.557360630728205%\n",
      "62.88648988575621%\n",
      "65.21561914078421%\n",
      "67.54474839581222%\n",
      "69.87387765084023%\n",
      "72.20300690586824%\n",
      "74.53213616089624%\n",
      "76.86126541592425%\n",
      "79.19039467095227%\n",
      "81.51952392598028%\n",
      "83.84865318100829%\n",
      "86.17778243603628%\n",
      "88.50691169106429%\n",
      "90.8360409460923%\n",
      "93.1651702011203%\n",
      "95.49429945614833%\n",
      "97.82342871117633%\n"
     ]
    }
   ],
   "source": [
    "# The soft-liquidation loss statistics are misleading in the current form.  E.g. if a user loses 20% of their collateral\n",
    "# and then pays back most debt and withdraws 80% collateral the statistics will say the user lost 100% of their collateral\n",
    "\n",
    "# Let's calculate the loss per day while the user is in soft liquidation.  We will remove time periods where the user\n",
    "# did an action e.g. deposited or withdrew collateral, paid back debt or borrowed more.\n",
    "\n",
    "# create a lossPctPerDay column which counts the % a user lost between snapshots standardized to a day\n",
    "data['lossPctPerDay'] = 0\n",
    "\n",
    "# count the times a user changes their collateral and debt\n",
    "data['debtActions'] = 0\n",
    "data['collateralActions'] = 0\n",
    "\n",
    "# count the days a user is in soft liquidation\n",
    "data['softLiqDays'] = 0\n",
    "\n",
    "\n",
    "# need to iterate through data to get the above data.  This is slow but works.\n",
    "i = 0\n",
    "length = len(data)\n",
    "\n",
    "while i < length:\n",
    "\n",
    "    # get the current row data\n",
    "    row = data.iloc[i]\n",
    "    loan_id = row['user'] + row['marketId'] + str(row['depositedCollateral'])\n",
    "    collat_value = (row['collateralUsd'] + row['stablecoin']) / row['oraclePrice']\n",
    "    deposited_collat = row['depositedCollateral']\n",
    "    debt = row['debt']\n",
    "    timestamp = row['timestamp']\n",
    "    \n",
    "    # it the current loan is the same as the previous loan, ie. same user, marketId and depositedCollateral\n",
    "    # then we can calculate the lost value and log it if they didn't change their debt\n",
    "    if i > 0 and prev_loan_id == loan_id:\n",
    "\n",
    "        # lost value is how much the user lost between snapshots in their collateral e.g., WETH\n",
    "        lost_value = prev_collat_value - collat_value\n",
    "        time_days_diff = (timestamp - prev_timestamp) / 86400\n",
    "\n",
    "        # if the debt changed by more than 2% then we log it as an action\n",
    "        if prev_debt > debt * 1.02 or prev_debt < debt * 0.98:\n",
    "            data.at[i, 'debtActions'] += 1\n",
    "        if prev_deposited_collat != deposited_collat:\n",
    "            data.at[i, 'collateralActions'] += 1\n",
    "        # else we log the lost value and the time between snapshots\n",
    "        elif lost_value > 0:\n",
    "            lossPctPerDay = lost_value / prev_collat_value / time_days_diff\n",
    "            data.at[i, 'softLiqDays'] = time_days_diff\n",
    "            data.at[i, 'lossPctPerDay'] = lossPctPerDay\n",
    "\n",
    "    # set the previous values to the current values\n",
    "    prev_collat_value = collat_value\n",
    "    prev_loan_id = loan_id\n",
    "    prev_timestamp = timestamp\n",
    "    prev_debt = debt\n",
    "    prev_deposited_collat = deposited_collat\n",
    "\n",
    "    # print progress every 10,000 rows\n",
    "    if i % 10000 == 0:\n",
    "        print(f\"{i / length * 100}%\")\n",
    "\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  n_range  entries  lossPctDay_min  lossPctDay_median  lossPctDay_mean  \\\n",
      "0     4-9    39357             0.0           0.001285         0.011455   \n",
      "1   10-19    17423             0.0           0.000360         0.007471   \n",
      "2   20-35     1027             0.0           0.000162         0.002533   \n",
      "3   36-50     1948             0.0           0.000092         0.005558   \n",
      "\n",
      "   lossPctDay_std  lossPctDay_max  softLiqDays  \n",
      "0        0.026747        0.389285  5634.910556  \n",
      "1        0.022235        0.430594  2412.896806  \n",
      "2        0.006361        0.064132   144.597500  \n",
      "3        0.013641        0.138341   259.940833  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_65591/3846588840.py:10: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  sl_n_stats_binned = softLiqData.groupby(['n_range']).agg({\n"
     ]
    }
   ],
   "source": [
    "# get real soft liquidation subset of data\n",
    "softLiqData = data.loc[data['real_softLiq']].copy()\n",
    "\n",
    "# create bins for the number of bands a user chose\n",
    "bins = [3, 9, 19, 35, 50]\n",
    "labels = ['4-9', '10-19', '20-35', '36-50']\n",
    "softLiqData.loc[:, 'n_range'] = pd.cut(softLiqData['n'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "# group the data by the number of bands a user chose\n",
    "sl_n_stats_binned = softLiqData.groupby(['n_range']).agg({\n",
    "    'timestamp': 'count',\n",
    "    'lossPctPerDay': ['min', 'median', 'mean', 'std', 'max'],\n",
    "    'softLiqDays': 'sum'\n",
    "}).reset_index(drop=False)\n",
    "\n",
    "# rename the columns and save to csv\n",
    "sl_n_stats_binned.columns = ['n_range', 'entries', 'lossPctDay_min', 'lossPctDay_median', 'lossPctDay_mean', 'lossPctDay_std', 'lossPctDay_max', 'softLiqDays']\n",
    "sl_n_stats_binned.to_csv('soft_liq_n_stats_binned.csv', index=False)\n",
    "print(sl_n_stats_binned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   n_range    loss_range  entries  softLiqDays\n",
      "0      4-9      0-0.001%     8427    32.120417\n",
      "1      4-9  0.001-0.005%      167    48.821111\n",
      "2      4-9   0.005-0.02%      537   148.822083\n",
      "3      4-9     0.02-0.1%     1739   587.548333\n",
      "4      4-9      0.1-0.5%     3791  1095.539861\n",
      "5      4-9        0.5-2%     4079  1073.534583\n",
      "6      4-9         2-10%     2073   455.897083\n",
      "7      4-9        10-50%      217    41.996806\n",
      "8      4-9          50%+        0     0.000000\n",
      "9    10-19      0-0.001%     4040    11.346667\n",
      "10   10-19  0.001-0.005%      102    35.520833\n",
      "11   10-19   0.005-0.02%      334   128.883611\n",
      "12   10-19     0.02-0.1%     1058   371.826389\n",
      "13   10-19      0.1-0.5%     1685   489.120833\n",
      "14   10-19        0.5-2%     1151   292.609167\n",
      "15   10-19         2-10%      517   105.742222\n",
      "16   10-19        10-50%       56    11.640417\n",
      "17   10-19          50%+        0     0.000000\n",
      "18   20-35      0-0.001%      318     2.478611\n",
      "19   20-35  0.001-0.005%       12     4.633194\n",
      "20   20-35   0.005-0.02%       39    12.616250\n",
      "21   20-35     0.02-0.1%      116    37.892500\n",
      "22   20-35      0.1-0.5%      132    37.199306\n",
      "23   20-35        0.5-2%       58    13.251667\n",
      "24   20-35         2-10%       13     3.070972\n",
      "25   20-35        10-50%        0     0.000000\n",
      "26   20-35          50%+        0     0.000000\n",
      "27   36-50      0-0.001%      208     3.919861\n",
      "28   36-50  0.001-0.005%       18     4.122500\n",
      "29   36-50   0.005-0.02%       46    13.420417\n",
      "30   36-50     0.02-0.1%       65    18.710833\n",
      "31   36-50      0.1-0.5%       60    15.876250\n",
      "32   36-50        0.5-2%       17     3.507361\n",
      "33   36-50         2-10%        1     0.329861\n",
      "34   36-50        10-50%        0     0.000000\n",
      "35   36-50          50%+        0     0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_70862/1288565374.py:14: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  sl_n_stats_binned = softLiqData.groupby(['n_range', 'loss_range']).agg({\n"
     ]
    }
   ],
   "source": [
    "# get real soft liquidation subset of data\n",
    "softLiqData = data.loc[data['real_softLiq']].copy()\n",
    "\n",
    "# create bins for the number of bands a user chose\n",
    "nBins = [3, 9, 19, 35, 50]\n",
    "nLabels = ['4-9', '10-19', '20-35', '36-50']\n",
    "softLiqData.loc[:, 'n_range'] = pd.cut(softLiqData['n'], bins=nBins, labels=nLabels, right=False)\n",
    "\n",
    "lossBins = [0, 0.00001, 0.00005, 0.0002, 0.001, 0.005, 0.02, 0.1, 0.5,9999]\n",
    "lossLabels = ['0-0.001%', '0.001-0.005%', '0.005-0.02%', '0.02-0.1%', '0.1-0.5%', '0.5-2%', '2-10%', '10-50%', '50%+']\n",
    "softLiqData.loc[:, 'loss_range'] = pd.cut(softLiqData['lossPctPerDay'], bins=lossBins, labels=lossLabels, right=False)\n",
    "\n",
    "# group the data by the number of bands a user chose\n",
    "sl_n_stats_binned = softLiqData.groupby(['n_range', 'loss_range']).agg({\n",
    "    'timestamp': 'count',\n",
    "    'softLiqDays': 'sum'\n",
    "}).reset_index(drop=False)\n",
    "\n",
    "# rename the columns and save to csv\n",
    "sl_n_stats_binned.columns = ['n_range', 'loss_range', 'entries', 'softLiqDays']\n",
    "sl_n_stats_binned.to_csv('soft_liq_n_stats_binned_with_loss_binned.csv', index=False)\n",
    "print(sl_n_stats_binned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "userActionData = data.copy()\n",
    "\n",
    "groupedLoans = userActionData.groupby(['user', 'marketId']).agg({\n",
    "    'debtActions': 'sum',\n",
    "    'collateralActions': 'sum',\n",
    "    'timestamp': ['min', 'max'],\n",
    "    'lossPct': 'max',\n",
    "    'health': 'min',\n",
    "    'n': 'max',\n",
    "    'debt': 'max',\n",
    "    'collateralUsd': 'max',\n",
    "    'softLiqDays': 'sum'\n",
    "}).reset_index(drop=False)\n",
    "\n",
    "groupedLoans.columns = ['user', 'marketId', 'debtActions', 'collateralActions', 'timestamp_min', 'timestamp_max', 'max_lossPct', 'min_health', 'max_n', 'max_debt', 'max_collateralUsd', 'softLiqDays']\n",
    "groupedLoans['days'] = (groupedLoans['timestamp_max'] - groupedLoans['timestamp_min']) / 86400\n",
    "groupedLoans.to_csv('grouped_loans.csv', index=False)\n",
    "pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
