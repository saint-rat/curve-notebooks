{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook reads user snapshot data from a csv and processes it to find the losses from soft liquidation in different band ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['basePrice', 'oraclePrice', 'activeBand', 'collateral', 'stablecoin',\n",
      "       'n', 'n1', 'n2', 'debt', 'depositedCollateral', 'health', 'loss',\n",
      "       'lossPct', 'timestamp', 'user', 'marketId', 'collateralName', 'softLiq',\n",
      "       'collateralUsd'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# if you want the data, run the get_data.ipynb notebook first, this will pull all the latest snapshots.\n",
    "data = pd.read_csv('user_snapshots.csv')\n",
    "print(data.columns)\n",
    "\n",
    "# find the portion of collateral in crvUSD and the collateral token as a percentage\n",
    "data['collateralPct'] = data['collateralUsd']/(data['collateralUsd']+data['stablecoin'])*100\n",
    "data['stablecoinPct'] = 100-data['collateralPct']\n",
    "\n",
    "# currently softLiq column is True even when under softliq, let's create new columns to show the real soft liquidation\n",
    "data['under_softLiq'] = data['collateralPct'].eq(0)\n",
    "data['real_softLiq'] = (~data['under_softLiq']) & (data['softLiq'])\n",
    "\n",
    "# find the loan to value ratio\n",
    "data['ltv'] = data['debt']/(data['collateralUsd']+data['stablecoin'])*100\n",
    "\n",
    "# sort the data by user, marketId and timestamp\n",
    "data = data.sort_values(by=['user', 'marketId', 'timestamp']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The soft-liquidation loss statistics are misleading in the current form.  E.g. if a user loses 20% of their collateral\n",
    "# and then pays back most debt and withdraws 80% collateral the statistics will say the user lost 100% of their collateral\n",
    "\n",
    "# Let's calculate the loss per day while the user is in soft liquidation.  We will remove time periods where the user\n",
    "# did an action e.g. deposited or withdrew collateral, paid back debt or borrowed more.\n",
    "\n",
    "# create a lossPctPerDay column which counts the % a user lost between snapshots standardized to a day\n",
    "data['lossPctPerDay'] = 0\n",
    "\n",
    "# count the times a user changes their collateral and debt\n",
    "data['debtActions'] = 0\n",
    "\n",
    "# count the days a user is in soft liquidation\n",
    "data['softLiqDays'] = 0\n",
    "\n",
    "\n",
    "# need to iterate through data to get the above data.  This is slow but works.\n",
    "i = 0\n",
    "length = len(data)\n",
    "\n",
    "while i < length:\n",
    "\n",
    "    # get the current row data\n",
    "    row = data.iloc[i]\n",
    "    loan_id = row['user'] + row['marketId'] + str(row['depositedCollateral'])\n",
    "    collat_value = (row['collateralUsd'] + row['stablecoin']) / row['oraclePrice']\n",
    "    debt = row['debt']\n",
    "    timestamp = row['timestamp']\n",
    "    \n",
    "    # it the current loan is the same as the previous loan, ie. same user, marketId and depositedCollateral\n",
    "    # then we can calculate the lost value and log it if they didn't change their debt\n",
    "    if i > 0 and prev_loan_id == loan_id:\n",
    "\n",
    "        # lost value is how much the user lost between snapshots in their collateral e.g., WETH\n",
    "        lost_value = prev_collat_value - collat_value\n",
    "        time_days_diff = (timestamp - prev_timestamp) / 86400\n",
    "\n",
    "        # if the debt changed by more than 2% then we log it as an action\n",
    "        if prev_debt > debt * 1.02 or prev_debt < debt * 0.98:\n",
    "            data.at[i, 'debtActions'] += 1\n",
    "        \n",
    "        # else we log the lost value and the time between snapshots\n",
    "        elif lost_value > 0:\n",
    "            lossPctPerDay = lost_value / prev_collat_value / time_days_diff\n",
    "            data.at[i, 'softLiqDays'] = time_days_diff\n",
    "            data.at[i, 'lossPctPerDay'] = lossPctPerDay\n",
    "\n",
    "    # set the previous values to the current values\n",
    "    prev_collat_value = collat_value\n",
    "    prev_loan_id = loan_id\n",
    "    prev_timestamp = timestamp\n",
    "    prev_debt = debt\n",
    "\n",
    "    # print progress every 10,000 rows\n",
    "    if i % 10000 == 0:\n",
    "        print(f\"{i / length * 100}%\")\n",
    "\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  n_range  entries  lossPctDay_min  lossPctDay_median  lossPctDay_mean  \\\n",
      "0     4-9    39340             0.0           0.000936         0.010990   \n",
      "1   10-19    17417             0.0           0.000341         0.007385   \n",
      "2   20-35     1023             0.0           0.000145         0.002491   \n",
      "3   36-50     1942             0.0           0.000077         0.005477   \n",
      "\n",
      "   lossPctDay_std  lossPctDay_max  softLiqDays  \n",
      "0        0.026158        0.389285  5411.026528  \n",
      "1        0.021998        0.430594  2389.507639  \n",
      "2        0.006218        0.064132   142.907917  \n",
      "3        0.013566        0.138341   257.078333  \n"
     ]
    }
   ],
   "source": [
    "# get real soft liquidation subset of data\n",
    "softLiqData = data.loc[data['real_softLiq']].copy()\n",
    "\n",
    "# create bins for the number of bands a user chose\n",
    "bins = [3, 9, 19, 35, 50]\n",
    "labels = ['4-9', '10-19', '20-35', '36-50']\n",
    "softLiqData.loc[:, 'n_range'] = pd.cut(softLiqData['n'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "# group the data by the number of bands a user chose\n",
    "sl_n_stats = softLiqData.groupby(['n_range']).agg({\n",
    "    'timestamp': 'count',\n",
    "    'lossPctPerDay': ['min', 'median', 'mean', 'std', 'max'],\n",
    "    'softLiqDays': 'sum'\n",
    "}).reset_index(drop=False)\n",
    "\n",
    "# rename the columns and save to csv\n",
    "sl_n_stats.columns = ['n_range', 'entries', 'lossPctDay_min', 'lossPctDay_median', 'lossPctDay_mean', 'lossPctDay_std', 'lossPctDay_max', 'softLiqDays']\n",
    "sl_n_stats.to_csv('grouped_soft_liq_stats.csv', index=False)\n",
    "print(sl_n_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This portion of the code was created to take band_snapshots and evaluate the soft-liquidation losses within bands through the snapshot periods.  It was found to not be a good estimate of the losses.  The snapshots were taken too wide apart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'timestamp', 'marketName', 'marketId', 'activeBand',\n",
      "       'basePrice', 'index', 'collateral', 'collateralUsd', 'stableCoin',\n",
      "       'oraclePrice'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('band_snapshots.csv')\n",
    "print(data.columns)\n",
    "\n",
    "# find the portion of collateral in crvUSD and the collateral token as a percentage\n",
    "data['collateralPct'] = data['collateralUsd']/(data['collateralUsd']+data['stableCoin'])*100\n",
    "data['stablecoinPct'] = 100-data['collateralPct']\n",
    "\n",
    "# sort the data by user, marketId and timestamp\n",
    "data = data.sort_values(by=['marketId', 'timestamp', 'index']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['lossPctPerDay'] = 0\n",
    "\n",
    "# count the days a user is in soft liquidation\n",
    "data['softLiqDays'] = 0\n",
    "\n",
    "# need to iterate through data to get the above data.  This is slow but works.\n",
    "i = 0\n",
    "dataActiveBands = data[(data['activeBand'] == data['index'])].copy()\n",
    "length = len(dataActiveBands)\n",
    "new_data = pd.DataFrame(columns=data.columns)\n",
    "\n",
    "while i < length:\n",
    "\n",
    "    # get the current row data\n",
    "    row = dataActiveBands.iloc[i].copy()\n",
    "    marketId = row['marketId']\n",
    "    activeBand = int(row['activeBand'])\n",
    "    timestamp = row['timestamp']\n",
    "    \n",
    "    collat_amount = (row['collateralUsd'] + row['stableCoin']) / row['oraclePrice']\n",
    "    collat_value = row['collateralUsd'] + row['stableCoin']\n",
    "\n",
    "    if i > 0 and marketId == prev_marketId:\n",
    "\n",
    "        if activeBand >= prev_activeBand:\n",
    "            ## price has dropped, calc loss in above bands\n",
    "            bandRange = len(range(prev_activeBand, activeBand+1))\n",
    "            for j in range(prev_activeBand, activeBand+1):\n",
    "                print(j)\n",
    "                prev_row = data[(data['marketId'] == marketId) & (data['timestamp'] == prev_timestamp) & (data['index'] == j)].copy()\n",
    "                cur_row = data[(data['marketId'] == marketId) & (data['timestamp'] == timestamp) & (data['index'] == j)].copy()\n",
    "                try:\n",
    "                    prev_basePrice = prev_row['basePrice'].values[0]\n",
    "                    basePrice = cur_row['basePrice'].values[0]\n",
    "                except:\n",
    "                    print(\"happened\")\n",
    "                    continue\n",
    "\n",
    "                if prev_row['activeBand'].values[0] == j:\n",
    "                    prev_price = prev_row['oraclePrice'].values[0]\n",
    "                elif prev_row['activeBand'].values[0] < j:\n",
    "                    prev_price = prev_basePrice * (99/100)**(j)\n",
    "                else:\n",
    "                    prev_price = prev_basePrice * (99/100)**(j+1)\n",
    "                prev_collat_amount = (prev_row['collateralUsd'].values[0] + prev_row['stableCoin'].values[0]) / prev_price\n",
    "                \n",
    "                if cur_row['activeBand'].values[0] == j:\n",
    "                    price = cur_row['oraclePrice'].values[0]\n",
    "                elif cur_row['activeBand'].values[0] < j:\n",
    "                    price = basePrice * (99/100)**(j)\n",
    "                else:\n",
    "                    price = basePrice * (99/100)**(j+1)\n",
    "\n",
    "                collat_amount = (cur_row['collateralUsd'].values[0] + cur_row['stableCoin'].values[0]) / price\n",
    "                prev_collat_amount = (prev_row['collateralUsd'].values[0] + prev_row['stableCoin'].values[0]) / prev_price\n",
    "                lost_amount = prev_collat_amount - collat_amount\n",
    "\n",
    "                time_days_diff = (timestamp - prev_timestamp) / bandRange / 86400\n",
    "                \n",
    "                # else we log the lost value and the time between snapshots\n",
    "                lossPctPerDay = lost_amount / prev_collat_amount / time_days_diff\n",
    "                if lossPctPerDay > 0 and lossPctPerDay < 0.10:\n",
    "                    cur_row.loc[cur_row.index[0], 'softLiqDays'] = time_days_diff\n",
    "                    cur_row.loc[cur_row.index[0], 'lossPctPerDay'] = lossPctPerDay\n",
    "                    if not cur_row['marketId'].isnull().any():\n",
    "                        print(f\"market: {cur_row['marketId'].values[0]}\")\n",
    "                        new_data = pd.concat([new_data, cur_row], ignore_index=True)\n",
    "                    else:\n",
    "                        pass\n",
    "\n",
    "    # set the previous values to the current values\n",
    "    prev_collat_amount = collat_amount\n",
    "    prev_marketId = marketId\n",
    "    prev_timestamp = timestamp\n",
    "    prev_activeBand = activeBand\n",
    "\n",
    "    i += 1\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          liq_range  entries  lossPctDay_min  lossPctDay_median  \\\n",
      "0             <1000      103    4.922813e-10       6.524876e-07   \n",
      "1         1000-5000       73    8.078126e-08       9.001594e-03   \n",
      "2        5000-20000      207    2.239918e-16       1.708548e-02   \n",
      "3      20000-100000      131    2.704587e-06       1.515267e-02   \n",
      "4     100000-500000      180    3.043710e-05       1.183717e-02   \n",
      "5    500000-2000000       95    1.769966e-04       2.179184e-02   \n",
      "6  2000000-10000000        0             NaN                NaN   \n",
      "\n",
      "   lossPctDay_mean  lossPctDay_std  lossPctDay_max  softLiqDays  \n",
      "0         0.004779        0.014503        0.083157   112.882824  \n",
      "1         0.019389        0.025856        0.094127    57.423658  \n",
      "2         0.026873        0.027027        0.096814   146.835847  \n",
      "3         0.023264        0.023442        0.099534    93.228032  \n",
      "4         0.022190        0.024037        0.097771   146.910199  \n",
      "5         0.029060        0.025399        0.097941    58.295457  \n",
      "6              NaN             NaN             NaN     0.000000  \n"
     ]
    }
   ],
   "source": [
    "# get real soft liquidation subset of data\n",
    "softLiqData = new_data.copy()\n",
    "softLiqData['liquidity'] = softLiqData['collateralUsd'] + softLiqData['stableCoin']\n",
    "\n",
    "# create bins for the number of bands a user chose\n",
    "bins = [0, 1000, 5000, 20000, 100000, 500000, 2000000, 10000000]\n",
    "labels = ['<1000', '1000-5000', '5000-20000', '20000-100000', '100000-500000', '500000-2000000', '2000000-10000000']\n",
    "softLiqData.loc[:, 'liq_range'] = pd.cut(softLiqData['liquidity'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "# group the data by the number of bands a user chose\n",
    "sl_liq_stats = softLiqData.groupby(['liq_range']).agg({\n",
    "    'timestamp': 'count',\n",
    "    'lossPctPerDay': ['min', 'median', 'mean', 'std', 'max'],\n",
    "    'softLiqDays': 'sum'\n",
    "}).reset_index(drop=False)\n",
    "\n",
    "# rename the columns and save to csv\n",
    "sl_liq_stats.columns = ['liq_range', 'entries', 'lossPctDay_min', 'lossPctDay_median', 'lossPctDay_mean', 'lossPctDay_std', 'lossPctDay_max', 'softLiqDays']\n",
    "sl_liq_stats.to_csv('liquidity_soft_liq_stats.csv', index=False)\n",
    "print(sl_liq_stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
